{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMKkvHSeINKxX9cFRrOTu9c"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"3WiKkjY2EfZY"},"outputs":[],"source":["!pip install -q kagglehub\n","\n","import os\n","import numpy as np\n","import torch\n","from torch.utils.data import DataLoader, Subset, WeightedRandomSampler\n","from torchvision import datasets, transforms, models\n","import torch.nn as nn\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Device:\", device)\n","\n","import kagglehub\n","\n","path = kagglehub.dataset_download(\"paultimothymooney/chest-xray-pneumonia\")\n","print(\"Base path from kagglehub:\", path)\n","\n","base_dir = None\n","for root, dirs, files in os.walk(path):\n","    if os.path.basename(root) == \"chest_xray\":\n","        base_dir = root\n","        break\n","\n","if base_dir is None:\n","    raise RuntimeError(\"لم يتم العثور على مجلد 'chest_xray' داخل المسار الذي أعاده kagglehub\")\n","\n","print(\"Found chest_xray folder at:\", base_dir)\n","\n","train_dir = os.path.join(base_dir, \"train\")\n","test_dir  = os.path.join(base_dir, \"test\")\n","\n","print(\"Train dir:\", train_dir)\n","print(\"Test dir :\", test_dir)\n","\n","train_transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","])\n","\n","test_transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","])\n","\n","full_train_dataset = datasets.ImageFolder(train_dir, transform=train_transform)\n","full_test_dataset  = datasets.ImageFolder(test_dir,  transform=test_transform)\n","\n","print(\"Full train size:\", len(full_train_dataset))\n","print(\"Full test size :\", len(full_test_dataset))\n","print(\"Classes:\", full_train_dataset.class_to_idx)\n","\n","train_size = min(1000, len(full_train_dataset))\n","test_size  = min(300, len(full_test_dataset))\n","\n","np.random.seed(42)\n","train_indices = np.random.choice(len(full_train_dataset), train_size, replace=False)\n","test_indices  = np.random.choice(len(full_test_dataset),  test_size,  replace=False)\n","\n","train_dataset = Subset(full_train_dataset, train_indices)\n","test_dataset  = Subset(full_test_dataset,  test_indices)\n","\n","batch_size = 32\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)\n","\n","print(\"Train subset size:\", len(train_dataset))\n","print(\"Test subset size :\", len(test_dataset))\n","\n","def build_model():\n","    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n","    model.fc = nn.Linear(model.fc.in_features, 2)\n","    return model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","def train_one_epoch(model, loader, optimizer, criterion, max_batches=None):\n","    model.train()\n","    correct = 0\n","    total = 0\n","    batch_count = 0\n","\n","    for images, labels in loader:\n","        images, labels = images.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        _, preds = torch.max(outputs, 1)\n","        correct += (preds == labels).sum().item()\n","        total += labels.size(0)\n","        batch_count += 1\n","\n","        if max_batches is not None and batch_count >= max_batches:\n","            break\n","\n","    return correct / total\n","\n","def evaluate(model, loader):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for images, labels in loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            _, preds = torch.max(outputs, 1)\n","            correct += (preds == labels).sum().item()\n","            total += labels.size(0)\n","\n","    return correct / total\n","\n","def get_probs(model, loader):\n","    model.eval()\n","    probs = []\n","    labels_list = []\n","    with torch.no_grad():\n","        for images, labels in loader:\n","            images = images.to(device)\n","            outputs = model(images)\n","            softmax_probs = torch.softmax(outputs, dim=1)[:, 1]\n","            probs.extend(softmax_probs.cpu().numpy())\n","            labels_list.extend(labels.numpy())\n","    return np.array(probs), np.array(labels_list)\n","\n","def get_preds(model, loader):\n","    model.eval()\n","    preds = []\n","    labels_list = []\n","    with torch.no_grad():\n","        for images, labels in loader:\n","            images = images.to(device)\n","            outputs = model(images)\n","            _, p = torch.max(outputs, 1)\n","            preds.extend(p.cpu().numpy())\n","            labels_list.extend(labels.numpy())\n","    return np.array(preds), np.array(labels_list)\n","\n","def compute_metrics_from_cm(cm):\n","    tn, fp, fn, tp = cm.ravel()\n","    accuracy = (tp + tn) / (tp + tn + fp + fn + 1e-8)\n","    sensitivity = tp / (tp + fn + 1e-8)\n","    specificity = tn / (tn + fp + 1e-8)\n","    return accuracy, sensitivity, specificity\n","\n","model_base = build_model()\n","optimizer_base = optim.Adam(model_base.parameters(), lr=1e-4)\n","\n","print(\"Training Baseline Model (FAST)...\")\n","num_epochs = 1\n","for epoch in range(num_epochs):\n","    train_acc = train_one_epoch(model_base, train_loader, optimizer_base, criterion, max_batches=30)\n","    test_acc  = evaluate(model_base, test_loader)\n","    print(f\"[Baseline] Epoch {epoch+1}: Train Acc={train_acc:.3f}, Test Acc={test_acc:.3f}\")\n","\n","targets = [full_train_dataset[i][1] for i in train_indices]\n","class_count = torch.bincount(torch.tensor(targets))\n","class_weights = 1.0 / class_count.float()\n","sample_weights = [class_weights[label] for label in targets]\n","sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n","\n","balanced_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n","\n","model_os = build_model()\n","optimizer_os = optim.Adam(model_os.parameters(), lr=1e-4)\n","\n","print(\"Training Oversampling Model (FAST)...\")\n","for epoch in range(num_epochs):\n","    train_acc_os = train_one_epoch(model_os, balanced_loader, optimizer_os, criterion, max_batches=30)\n","    test_acc_os  = evaluate(model_os, test_loader)\n","    print(f\"[OS] Epoch {epoch+1}: Train Acc={train_acc_os:.3f}, Test Acc={test_acc_os:.3f}\")\n","\n","probs_b, labels = get_probs(model_base, test_loader)\n","probs_os, _      = get_probs(model_os,   test_loader)\n","\n","auc_b  = roc_auc_score(labels, probs_b)\n","auc_os = roc_auc_score(labels, probs_os)\n","\n","print(f\"Baseline AUC     : {auc_b:.3f}\")\n","print(f\"Oversampling AUC : {auc_os:.3f}\")\n","\n","fpr_b, tpr_b, _ = roc_curve(labels, probs_b)\n","fpr_os, tpr_os, _ = roc_curve(labels, probs_os)\n","\n","plt.figure(figsize=(7,5))\n","plt.plot(fpr_b, tpr_b, label=f\"Baseline (AUC={auc_b:.2f})\")\n","plt.plot(fpr_os, tpr_os, label=f\"Oversampling (AUC={auc_os:.2f})\")\n","plt.plot([0,1], [0,1], 'k--')\n","plt.title(\"ROC Curve Comparison\")\n","plt.xlabel(\"False Positive Rate\")\n","plt.ylabel(\"True Positive Rate\")\n","plt.legend()\n","plt.grid()\n","plt.show()\n","\n","# Confusion Matrix + Accuracy/Sensitivity/Specificity\n","\n","preds_b, labels_b = get_preds(model_base, test_loader)\n","preds_os, labels_os = get_preds(model_os, test_loader)\n","\n","cm_b  = confusion_matrix(labels_b, preds_b)\n","cm_os = confusion_matrix(labels_os, preds_os)\n","\n","print(\"Baseline Confusion Matrix:\\n\", cm_b)\n","print(\"Oversampling Confusion Matrix:\\n\", cm_os)\n","\n","acc_b, sens_b, spec_b = compute_metrics_from_cm(cm_b)\n","acc_os, sens_os, spec_os = compute_metrics_from_cm(cm_os)\n","\n","print(\"\\n=== Baseline Metrics ===\")\n","print(f\"Accuracy   : {acc_b:.3f}\")\n","print(f\"Sensitivity: {sens_b:.3f}\")\n","print(f\"Specificity: {spec_b:.3f}\")\n","\n","print(\"\\n=== Oversampling Metrics ===\")\n","print(f\"Accuracy   : {acc_os:.3f}\")\n","print(f\"Sensitivity: {sens_os:.3f}\")\n","print(f\"Specificity: {spec_os:.3f}\")\n"]}]}